{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excel file has been created: D:/Workspace/EducationQ_Benchmark/src/data/output/EduQ-Bench_Student-llama31-70b-instruct/MMLU-Pro/comprehensive_evaluation_results_1.0.0_20241012_060906.xlsx\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "def comprehensive_json_to_excel(json_file_path, excel_file_path):\n",
    "    # 读取JSON文件\n",
    "    with open(json_file_path, 'r', encoding='utf-8') as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    # 准备存储所有行的列表\n",
    "    rows = []\n",
    "\n",
    "    # 定义评估维度\n",
    "    interaction_dimensions = [\n",
    "        'Assessment Effectiveness',\n",
    "        'Questioning Effectiveness',\n",
    "        'Feedback Effectiveness',\n",
    "        'Instructional Adaptation Effectiveness',\n",
    "        'Learning Objective Achievement Effectiveness'\n",
    "    ]\n",
    "    \n",
    "    teacher_questions_dimensions = [\n",
    "        'Question Relevance',\n",
    "        'Cognitive Level',\n",
    "        'Knowledge Dimension',\n",
    "        'Question Diversity',\n",
    "        'Scaffolding Progression',\n",
    "        'Metacognitive Promotion'\n",
    "    ]\n",
    "    \n",
    "    student_responses_dimensions = [\n",
    "        'Response Relevance',\n",
    "        'Cognitive Level Demonstration',\n",
    "        'Knowledge Dimension Integration',\n",
    "        'Response Diversity',\n",
    "        'Elaboration Progression',\n",
    "        'Metacognitive Reflection'\n",
    "    ]\n",
    "\n",
    "    # 遍历JSON数据\n",
    "    for question_id, teacher_pairs in data.items():\n",
    "        for teacher_pair, evaluation in teacher_pairs.items():\n",
    "            teacher_a_name, teacher_b_name = teacher_pair.split('_vs_')\n",
    "\n",
    "            # 为每个教师创建一行\n",
    "            for teacher_name in [teacher_a_name, teacher_b_name]:\n",
    "                row = {\n",
    "                    'question_id': question_id,\n",
    "                    'teacher_pair': teacher_pair,\n",
    "                    'teacher_name': teacher_name\n",
    "                }\n",
    "\n",
    "                # 添加interaction_analysis的评估\n",
    "                interaction_data = evaluation['interaction_analysis'][teacher_name]\n",
    "                for dimension in interaction_dimensions:\n",
    "                    row[f'interaction_{dimension.lower().replace(\" \", \"_\")}_analysis'] = interaction_data[dimension]['analysis']\n",
    "                    row[f'interaction_{dimension.lower().replace(\" \", \"_\")}_score'] = interaction_data[dimension]['score']\n",
    "\n",
    "                # 添加teacher_questions_analysis的评估\n",
    "                teacher_questions_data = evaluation['teacher_questions_analysis'][teacher_name]\n",
    "                for dimension in teacher_questions_dimensions:\n",
    "                    row[f'teacher_questions_{dimension.lower().replace(\" \", \"_\")}_analysis'] = teacher_questions_data[dimension]['analysis']\n",
    "                    row[f'teacher_questions_{dimension.lower().replace(\" \", \"_\")}_score'] = teacher_questions_data[dimension]['score']\n",
    "\n",
    "                # 添加student_responses_analysis的评估\n",
    "                student_responses_data = evaluation['student_responses_analysis'][teacher_name]\n",
    "                for dimension in student_responses_dimensions:\n",
    "                    row[f'student_responses_{dimension.lower().replace(\" \", \"_\")}_analysis'] = student_responses_data[dimension]['analysis']\n",
    "                    row[f'student_responses_{dimension.lower().replace(\" \", \"_\")}_score'] = student_responses_data[dimension]['score']\n",
    "\n",
    "                # 添加各个评估的verdict信息\n",
    "                for eval_type in ['interaction_analysis', 'teacher_questions_analysis', 'student_responses_analysis']:\n",
    "                    row[f'{eval_type}_verdict_analysis'] = evaluation[eval_type]['verdict']['analysis']\n",
    "                    row[f'{eval_type}_verdict_choice'] = evaluation[eval_type]['verdict']['choice']\n",
    "\n",
    "                rows.append(row)\n",
    "\n",
    "    # 创建DataFrame\n",
    "    df = pd.DataFrame(rows)\n",
    "\n",
    "    # 保存为Excel文件\n",
    "    df.to_excel(excel_file_path, index=False)\n",
    "    print(f\"Excel file has been created: {excel_file_path}\")\n",
    "\n",
    "# 使用函数\n",
    "json_file_path = 'D:/Workspace/EducationQ_Benchmark/src/data/output/EduQ-Bench_Student-llama31-70b-instruct/MMLU-Pro/comprehensive_evaluation_results_1.0.0_20241012_060906.json'\n",
    "excel_file_path = 'D:/Workspace/EducationQ_Benchmark/src/data/output/EduQ-Bench_Student-llama31-70b-instruct/MMLU-Pro/comprehensive_evaluation_results_1.0.0_20241012_060906.xlsx'\n",
    "comprehensive_json_to_excel(json_file_path, excel_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excel file has been created: D:/Workspace/EducationQ_Benchmark/src/data/output/EduQ-Bench_Student-llama31-70b-instruct/MMLU-Pro/comprehensive_evaluation_results_1.0.0_20241012_060906_v2.xlsx\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "def comprehensive_json_to_excel(json_file_path, excel_file_path):\n",
    "    # 读取JSON文件\n",
    "    with open(json_file_path, 'r', encoding='utf-8') as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    # 准备存储所有行的列表\n",
    "    rows = []\n",
    "\n",
    "    # 定义评估维度\n",
    "    dimensions = {\n",
    "        'interaction': [\n",
    "            'Assessment Effectiveness',\n",
    "            'Questioning Effectiveness',\n",
    "            'Feedback Effectiveness',\n",
    "            'Instructional Adaptation Effectiveness',\n",
    "            'Learning Objective Achievement Effectiveness'\n",
    "        ],\n",
    "        'teacher_questions': [\n",
    "            'Question Relevance',\n",
    "            'Cognitive Level',\n",
    "            'Knowledge Dimension',\n",
    "            'Question Diversity',\n",
    "            'Scaffolding Progression',\n",
    "            'Metacognitive Promotion'\n",
    "        ],\n",
    "        'student_responses': [\n",
    "            'Response Relevance',\n",
    "            'Cognitive Level Demonstration',\n",
    "            'Knowledge Dimension Integration',\n",
    "            'Response Diversity',\n",
    "            'Elaboration Progression',\n",
    "            'Metacognitive Reflection'\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    # 遍历JSON数据\n",
    "    for question_id, teacher_pairs in data.items():\n",
    "        for teacher_pair, evaluation in teacher_pairs.items():\n",
    "            teacher_a_name, teacher_b_name = teacher_pair.split('_vs_')\n",
    "\n",
    "            row = {\n",
    "                'question_id': question_id,\n",
    "                'teacher_pair': teacher_pair,\n",
    "                'teacher_a_name': teacher_a_name,\n",
    "                'teacher_b_name': teacher_b_name\n",
    "            }\n",
    "\n",
    "            for eval_type in ['interaction', 'teacher_questions', 'student_responses']:\n",
    "                eval_key = f'{eval_type}_analysis'\n",
    "                for teacher in [teacher_a_name, teacher_b_name]:\n",
    "                    teacher_data = evaluation[eval_key][teacher]\n",
    "                    for dimension in dimensions[eval_type]:\n",
    "                        dim_key = dimension.lower().replace(' ', '_')\n",
    "                        row[f'{eval_type}_{teacher}_{dim_key}_analysis'] = teacher_data[dimension]['analysis']\n",
    "                        row[f'{eval_type}_{teacher}_{dim_key}_score'] = teacher_data[dimension]['score']\n",
    "\n",
    "                # 添加verdict信息\n",
    "                row[f'{eval_type}_verdict_analysis'] = evaluation[eval_key]['verdict']['analysis']\n",
    "                row[f'{eval_type}_verdict_choice'] = evaluation[eval_key]['verdict']['choice']\n",
    "\n",
    "            rows.append(row)\n",
    "\n",
    "    # 创建DataFrame\n",
    "    df = pd.DataFrame(rows)\n",
    "\n",
    "    # 保存为Excel文件\n",
    "    df.to_excel(excel_file_path, index=False)\n",
    "    print(f\"Excel file has been created: {excel_file_path}\")\n",
    "\n",
    "# 使用函数\n",
    "json_file_path = 'D:/Workspace/EducationQ_Benchmark/src/data/output/EduQ-Bench_Student-llama31-70b-instruct/MMLU-Pro/comprehensive_evaluation_results_1.0.0_20241012_060906.json'\n",
    "excel_file_path = 'D:/Workspace/EducationQ_Benchmark/src/data/output/EduQ-Bench_Student-llama31-70b-instruct/MMLU-Pro/comprehensive_evaluation_results_1.0.0_20241012_060906_v2.xlsx'\n",
    "comprehensive_json_to_excel(json_file_path, excel_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excel file has been created: D:/Workspace/EducationQ_Benchmark/src/data/output/EduQ-Bench_Student-llama31-70b-instruct/MMLU-Pro/comprehensive_evaluation_results_1.0.0_20241012_060906_v3.xlsx\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "def comprehensive_json_to_excel(json_file_path, excel_file_path):\n",
    "    with open(json_file_path, 'r', encoding='utf-8') as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    rows = []\n",
    "\n",
    "    dimensions = {\n",
    "        'interaction': [\n",
    "            'Assessment Effectiveness',\n",
    "            'Questioning Effectiveness',\n",
    "            'Feedback Effectiveness',\n",
    "            'Instructional Adaptation Effectiveness',\n",
    "            'Learning Objective Achievement Effectiveness'\n",
    "        ],\n",
    "        'teacher_questions': [\n",
    "            'Question Relevance',\n",
    "            'Cognitive Level',\n",
    "            'Knowledge Dimension',\n",
    "            'Question Diversity',\n",
    "            'Scaffolding Progression',\n",
    "            'Metacognitive Promotion'\n",
    "        ],\n",
    "        'student_responses': [\n",
    "            'Response Relevance',\n",
    "            'Cognitive Level Demonstration',\n",
    "            'Knowledge Dimension Integration',\n",
    "            'Response Diversity',\n",
    "            'Elaboration Progression',\n",
    "            'Metacognitive Reflection'\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    for question_id, teacher_pairs in data.items():\n",
    "        for teacher_pair, evaluation in teacher_pairs.items():\n",
    "            teacher_a_name, teacher_b_name = teacher_pair.split('_vs_')\n",
    "\n",
    "            row = {\n",
    "                'question_id': question_id,\n",
    "                'teacher_pair': teacher_pair,\n",
    "                'teacher_a_name': teacher_a_name,\n",
    "                'teacher_b_name': teacher_b_name\n",
    "            }\n",
    "\n",
    "            for eval_type in ['interaction', 'teacher_questions', 'student_responses']:\n",
    "                eval_key = f'{eval_type}_analysis'\n",
    "                for teacher in [teacher_a_name, teacher_b_name]:\n",
    "                    teacher_data = evaluation[eval_key][teacher]\n",
    "                    for dimension in dimensions[eval_type]:\n",
    "                        dim_key = dimension.lower().replace(' ', '_')\n",
    "                        row[f'{teacher}_{eval_type}_{dim_key}_analysis'] = teacher_data[dimension]['analysis']\n",
    "                        row[f'{teacher}_{eval_type}_{dim_key}_score'] = teacher_data[dimension]['score']\n",
    "\n",
    "                # 添加verdict信息\n",
    "                row[f'{eval_type}_verdict_analysis'] = evaluation[eval_key]['verdict']['analysis']\n",
    "                row[f'{eval_type}_verdict_choice'] = evaluation[eval_key]['verdict']['choice']\n",
    "\n",
    "            rows.append(row)\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "\n",
    "    # 重新排列列的顺序\n",
    "    column_order = ['question_id', 'teacher_pair', 'teacher_a_name', 'teacher_b_name']\n",
    "    for eval_type in ['interaction', 'teacher_questions', 'student_responses']:\n",
    "        for teacher in [teacher_a_name, teacher_b_name]:\n",
    "            for dimension in dimensions[eval_type]:\n",
    "                dim_key = dimension.lower().replace(' ', '_')\n",
    "                column_order.extend([f'{teacher}_{eval_type}_{dim_key}_analysis', f'{teacher}_{eval_type}_{dim_key}_score'])\n",
    "        column_order.extend([f'{eval_type}_verdict_analysis', f'{eval_type}_verdict_choice'])\n",
    "\n",
    "    df = df[column_order]\n",
    "\n",
    "    df.to_excel(excel_file_path, index=False)\n",
    "    print(f\"Excel file has been created: {excel_file_path}\")\n",
    "\n",
    "# 使用函数\n",
    "json_file_path = 'D:/Workspace/EducationQ_Benchmark/src/data/output/EduQ-Bench_Student-llama31-70b-instruct/MMLU-Pro/comprehensive_evaluation_results_1.0.0_20241012_060906.json'\n",
    "excel_file_path = 'D:/Workspace/EducationQ_Benchmark/src/data/output/EduQ-Bench_Student-llama31-70b-instruct/MMLU-Pro/comprehensive_evaluation_results_1.0.0_20241012_060906_v3.xlsx'\n",
    "comprehensive_json_to_excel(json_file_path, excel_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excel file has been created: D:/Workspace/EducationQ_Benchmark/src/data/output/EduQ-Bench_Student-llama31-70b-instruct/MMLU-Pro/comprehensive_evaluation_results_1.0.0_20241012_060906_v4.xlsx\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "def comprehensive_json_to_excel(json_file_path, excel_file_path):\n",
    "    # 读取JSON文件\n",
    "    with open(json_file_path, 'r', encoding='utf-8') as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    # 准备存储所有行的列表\n",
    "    rows = []\n",
    "\n",
    "    # 定义评估维度\n",
    "    dimensions = {\n",
    "        'interaction': [\n",
    "            'Assessment Effectiveness',\n",
    "            'Questioning Effectiveness',\n",
    "            'Feedback Effectiveness',\n",
    "            'Instructional Adaptation Effectiveness',\n",
    "            'Learning Objective Achievement Effectiveness'\n",
    "        ],\n",
    "        'teacher_questions': [\n",
    "            'Question Relevance',\n",
    "            'Cognitive Level',\n",
    "            'Knowledge Dimension',\n",
    "            'Question Diversity',\n",
    "            'Scaffolding Progression',\n",
    "            'Metacognitive Promotion'\n",
    "        ],\n",
    "        'student_responses': [\n",
    "            'Response Relevance',\n",
    "            'Cognitive Level Demonstration',\n",
    "            'Knowledge Dimension Integration',\n",
    "            'Response Diversity',\n",
    "            'Elaboration Progression',\n",
    "            'Metacognitive Reflection'\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    # 遍历JSON数据\n",
    "    for question_id, teacher_pairs in data.items():\n",
    "        for teacher_pair, evaluation in teacher_pairs.items():\n",
    "            teacher_a_name, teacher_b_name = teacher_pair.split('_vs_')\n",
    "\n",
    "            row = {\n",
    "                'question_id': question_id,\n",
    "                'teacher_pair': teacher_pair,\n",
    "                'teacher_a_name': teacher_a_name,\n",
    "                'teacher_b_name': teacher_b_name\n",
    "            }\n",
    "\n",
    "            for eval_type in ['interaction', 'teacher_questions', 'student_responses']:\n",
    "                eval_key = f'{eval_type}_analysis'\n",
    "                for i, teacher in enumerate([teacher_a_name, teacher_b_name]):\n",
    "                    teacher_label = f'teacher_{\"a\" if i == 0 else \"b\"}'\n",
    "                    teacher_data = evaluation[eval_key][teacher]\n",
    "                    for dimension in dimensions[eval_type]:\n",
    "                        dim_key = dimension.lower().replace(' ', '_')\n",
    "                        row[f'{teacher_label}_{eval_type}_{dim_key}_analysis'] = teacher_data[dimension]['analysis']\n",
    "                        row[f'{teacher_label}_{eval_type}_{dim_key}_score'] = teacher_data[dimension]['score']\n",
    "\n",
    "                # 添加verdict信息\n",
    "                row[f'{eval_type}_verdict_analysis'] = evaluation[eval_key]['verdict']['analysis']\n",
    "                row[f'{eval_type}_verdict_choice'] = evaluation[eval_key]['verdict']['choice']\n",
    "\n",
    "            rows.append(row)\n",
    "\n",
    "    # 创建DataFrame\n",
    "    df = pd.DataFrame(rows)\n",
    "\n",
    "    # 重新排列列的顺序\n",
    "    column_order = ['question_id', 'teacher_pair', 'teacher_a_name', 'teacher_b_name']\n",
    "    for eval_type in ['interaction', 'teacher_questions', 'student_responses']:\n",
    "        for teacher in ['teacher_a', 'teacher_b']:\n",
    "            for dimension in dimensions[eval_type]:\n",
    "                dim_key = dimension.lower().replace(' ', '_')\n",
    "                column_order.extend([\n",
    "                    f'{teacher}_{eval_type}_{dim_key}_analysis',\n",
    "                    f'{teacher}_{eval_type}_{dim_key}_score'\n",
    "                ])\n",
    "        column_order.extend([f'{eval_type}_verdict_analysis', f'{eval_type}_verdict_choice'])\n",
    "\n",
    "    df = df[column_order]\n",
    "\n",
    "    # 保存为Excel文件\n",
    "    df.to_excel(excel_file_path, index=False)\n",
    "    print(f\"Excel file has been created: {excel_file_path}\")\n",
    "\n",
    "# 使用函数\n",
    "json_file_path = 'D:/Workspace/EducationQ_Benchmark/src/data/output/EduQ-Bench_Student-llama31-70b-instruct/MMLU-Pro/comprehensive_evaluation_results_1.0.0_20241012_060906.json'\n",
    "excel_file_path = 'D:/Workspace/EducationQ_Benchmark/src/data/output/EduQ-Bench_Student-llama31-70b-instruct/MMLU-Pro/comprehensive_evaluation_results_1.0.0_20241012_060906_v4.xlsx'\n",
    "comprehensive_json_to_excel(json_file_path, excel_file_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "teacher",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
