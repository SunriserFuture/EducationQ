## "DATASET_TYPE": "gpqa", "mmlu-pro"
## "DATASET_NAME": "gpqa_diamond.csv", "gpqa_experts.csv", "gpqa_extended.csv", "gpqa_main.csv", "TIGER-Lab/MMLU-Pro"


DATASET_TYPE: "mmlu-pro"
DATASET_NAME: "TIGER-Lab/MMLU-Pro"
OUTPUT_PATH: "your_output_path"
EXPERIMENT_VERSION: "1.0.0"
API_CALL_MAX_RETRIES: 10
API_CALL_RETRY_DELAY: 5
PARALLEL_TASKS: 15
NUM_INTERACTIONS: 5
NUM_IF_FEW_SHOTS: 5
SELECTED_CATEGORIES: []
SELECTED_QUESTION_ID: [10822, 10935, 10944, 10955, 11025]
FIRST_QUESTIONS_SIZE: null
QUESTIONS_SAMPLE_SIZE: null
LOGGING_LEVEL: "INFO"
## "INFO", "WARNING", "ERROR"

TEACHER_CONFIGS:
  - name: "Teacher1"
    model: "meta-llama/llama-3.1-70b-instruct"
    api_key: "your_api_key"
    base_url: "your_api_url"
    temperature: 0.0
    max_tokens: 1024
    use_few_shot: true
    recommended_question_token_limit: 150
    recommended_education_theory: null
    max_tokens_rerun_threshold_percentage: 0.8
    question_retries: 3

  - name: "Teacher_gpt4o_mini"
    model: "openai/gpt-4o-mini"
    api_key: "your_api_key"
    base_url: "your_api_url"
    temperature: 0.0
    max_tokens: 1024
    use_few_shot: true
    recommended_question_token_limit: 150
    recommended_education_theory: null
    max_tokens_rerun_threshold_percentage: 0.8
    question_retries: 5

STUDENT_CONFIGS:
  - name: "Student1"
    model: "meta-llama/llama-3.1-70b-instruct"
    api_key: "your_api_key"
    base_url: "your_api_url"
    temperature: 0.0
    answer_max_tokens: 1024
    test_max_tokens: 2048
    use_few_shot: false
    include_pretest_info: true
    recommended_answer_token_limit: 150
    recommended_test_token_limit: 1024
    max_tokens_rerun_threshold_percentage: 0.8
    answer_retries: 3

  - name: "Student2"
    model: "meta-llama/llama-3.1-70b-instruct"
    api_key: "your_api_key"
    base_url: "your_api_url"
    temperature: 0.0
    answer_max_tokens: 1024
    test_max_tokens: 2048
    use_few_shot: false
    include_pretest_info: true
    recommended_answer_token_limit: 150
    recommended_test_token_limit: 1024
    max_tokens_rerun_threshold_percentage: 0.8
    answer_retries: 3

EVALUATOR_CONFIG:
  name: "Evaluator"
  model: "openai/gpt-4o-mini"
  api_key: "your_openai_api_key"
  base_url: "your_api_url"
  temperature: 0.0
  max_tokens: 4096
  use_few_shot: false